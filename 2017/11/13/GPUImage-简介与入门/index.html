
 <!DOCTYPE HTML>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  
    <title>GPUImage 简介与入门 | DevZhang的博客小屋</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="CSAMEN">
    

    
    <meta name="description" content="概述GPUImage 是一个 iOS 框架，主要提供 GPU 过滤和一些其他的作用于 images, live camera video, 和 movies。相对于 Core Image ，GPUImage 允许我们自定义过滤器，并且提供更简单的接口，但是缺少 Core Image 中一些更先进的功能，比如脸部检测。GPUImage 封装了我们日常开发中可能用到的大量的常用的 task 去">
<meta property="og:type" content="article">
<meta property="og:title" content="GPUImage 简介与入门">
<meta property="og:url" content="http://yoursite.com/2017/11/13/GPUImage-简介与入门/index.html">
<meta property="og:site_name" content="DevZhang的博客小屋">
<meta property="og:description" content="概述GPUImage 是一个 iOS 框架，主要提供 GPU 过滤和一些其他的作用于 images, live camera video, 和 movies。相对于 Core Image ，GPUImage 允许我们自定义过滤器，并且提供更简单的接口，但是缺少 Core Image 中一些更先进的功能，比如脸部检测。GPUImage 封装了我们日常开发中可能用到的大量的常用的 task 去">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/304825-5faefe55f9296071.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/304825-84ff54fb516a70ce.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:updated_time" content="2017-11-14T09:59:14.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="GPUImage 简介与入门">
<meta name="twitter:description" content="概述GPUImage 是一个 iOS 框架，主要提供 GPU 过滤和一些其他的作用于 images, live camera video, 和 movies。相对于 Core Image ，GPUImage 允许我们自定义过滤器，并且提供更简单的接口，但是缺少 Core Image 中一些更先进的功能，比如脸部检测。GPUImage 封装了我们日常开发中可能用到的大量的常用的 task 去">
<meta name="twitter:image" content="http://upload-images.jianshu.io/upload_images/304825-5faefe55f9296071.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">

    
    <link rel="alternative" href="/atom.xml" title="DevZhang的博客小屋" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/jacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/jacman.jpg">
    
    <link rel="stylesheet" href="/css/style.css">
</head>

  <body>
    <header>
      
<div>
		
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="DevZhang的博客小屋">DevZhang的博客小屋</a></h1>
				<h2 class="blog-motto">有生之莲</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="菜单">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">Home</a></li>
					
						<li><a href="/archives">Archives</a></li>
					
						<li><a href="/about">About</a></li>
					
					<li>
 					
					<form class="search" action="//google.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" name="q" autocomplete="off" maxlength="20" placeholder="搜索" />
						<input type="hidden" name="q" value="site:yoursite.com">
					</form>
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main" class="post" itemscope itemprop="blogPost">
  
	<article itemprop="articleBody"> 
		<header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/11/13/GPUImage-简介与入门/" title="GPUImage 简介与入门" itemprop="url">GPUImage 简介与入门</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="CSAMEN" target="_blank" itemprop="author">CSAMEN</a>
		
  <p class="article-time">
    <time datetime="2017-11-13T07:16:37.000Z" itemprop="datePublished"> 发表于 2017-11-13</time>
    
  </p>
</header>
	<div class="article-content">
		
		<div id="toc" class="toc-article">
			<strong class="toc-title">文章目录</strong>
		
			<ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#概述"><span class="toc-number">1.</span> <span class="toc-text">概述</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#基本架构"><span class="toc-number">2.</span> <span class="toc-text">基本架构</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#执行一些普通任务"><span class="toc-number">3.</span> <span class="toc-text">执行一些普通任务</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#过滤实时摄像（相机实时）"><span class="toc-number">3.1.</span> <span class="toc-text">过滤实时摄像（相机实时）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#捕捉和过滤静态图片（相机拍照）"><span class="toc-number">3.2.</span> <span class="toc-text">捕捉和过滤静态图片（相机拍照）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#加工静态图片"><span class="toc-number">3.3.</span> <span class="toc-text">加工静态图片</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#自定义过滤器"><span class="toc-number">3.4.</span> <span class="toc-text">自定义过滤器</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#过滤并且重新编码一个影片"><span class="toc-number">3.5.</span> <span class="toc-text">过滤并且重新编码一个影片</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#直播中利用-GPUImage-处理过程"><span class="toc-number">4.</span> <span class="toc-text">直播中利用 GPUImage 处理过程</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#GPUImage-处理画面的原理"><span class="toc-number">5.</span> <span class="toc-text">GPUImage 处理画面的原理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#一个美颜算法的例子"><span class="toc-number">6.</span> <span class="toc-text">一个美颜算法的例子</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#参考"><span class="toc-number">7.</span> <span class="toc-text">参考</span></a></li></ol>
		
		</div>
		
		<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>GPUImage 是一个 iOS 框架，主要提供 GPU 过滤和一些其他的作用于 images, live camera video, 和 movies。相对于 Core Image ，GPUImage 允许我们自定义过滤器，并且提供更简单的接口，但是缺少 Core Image 中一些更先进的功能，比如脸部检测。GPUImage 封装了我们日常开发中可能用到的大量的常用的 task 去加工图片或者视频，降低了开发难度，这样我们就不需要具备很多 OpenGL ES 2.0 的知识也能实现日常功能。<a href="https://github.com/BradLarson/GPUImage" target="_blank" rel="external">GUPImage 地址</a></p>
<h1 id="基本架构"><a href="#基本架构" class="headerlink" title="基本架构"></a>基本架构</h1><p>GPUImage 使用 OpenGL ES 2.0 着色器去执行图片和视频的操作，同时通过更加简单的 OC 的接口隐藏了复杂的  OpenGL ES 的接口。对于用户更加的友好，这些接口可以使得我们去定义图像和视频的输入源，使得过滤器以一个链式的形式，最终发送一个处理过的图像或者视频到屏幕，UIImage 或者 Movie。</p>
<p>图片或者视频帧都是来自源对象的，基类是 GPUImageOutput ，它包含了下面 4 种类别:</p>
<ul>
<li><p>GPUImageVideoCamera（相机的视频直播）</p>
</li>
<li><p>GPUImageStillCamera (相机拍摄的照片)</p>
</li>
<li><p>GPUImagePicture (静态图片)</p>
</li>
<li><p>GPUImageMovie (movies)</p>
</li>
</ul>
<p>源对象上传静态图像到 OpenGL ES 作为纹理，然后处理那些纹理通过加工链传递到下一个对象。</p>
<p><code>GPUImageVideoCamera -&gt; GPUImageSepiaFilter -&gt; GPUImageView</code></p>
<h1 id="执行一些普通任务"><a href="#执行一些普通任务" class="headerlink" title="执行一些普通任务"></a>执行一些普通任务</h1><h2 id="过滤实时摄像（相机实时）"><a href="#过滤实时摄像（相机实时）" class="headerlink" title="过滤实时摄像（相机实时）"></a>过滤实时摄像（相机实时）</h2><figure class="highlight mm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">GP<span class="built_in">UImageVideoCamera</span> *videoCamera = [[GP<span class="built_in">UImageVideoCamera</span> alloc] initWithSessionPreset:<span class="built_in">AVCaptureSessionPreset640x480</span> cameraPosition:<span class="built_in">AVCaptureDevicePositionBack</span>];</span><br><span class="line">videoCamera.outputImageOrientation = <span class="built_in">UIInterfaceOrientationPortrait</span>;</span><br><span class="line"></span><br><span class="line">GP<span class="built_in">UImageFilter</span> *customFilter = [[GP<span class="built_in">UImageFilter</span> alloc] initWithFragmentShaderFromFile:<span class="string">@"CustomShader"</span>];</span><br><span class="line">GP<span class="built_in">UImageView</span> *filteredVideoView = [[GP<span class="built_in">UImageView</span> alloc] initWithFrame:<span class="built_in">CGRectMake</span>(<span class="number">0.0</span>, <span class="number">0.0</span>, viewWidth, viewHeight)];</span><br><span class="line"></span><br><span class="line"><span class="comment">// Add the view somewhere so it's visible</span></span><br><span class="line"></span><br><span class="line">[videoCamera addTarget:customFilter];</span><br><span class="line">[customFilter addTarget:filteredVideoView];</span><br><span class="line"></span><br><span class="line">[videoCamera startCameraCapture];</span><br></pre></td></tr></table></figure>
<h2 id="捕捉和过滤静态图片（相机拍照）"><a href="#捕捉和过滤静态图片（相机拍照）" class="headerlink" title="捕捉和过滤静态图片（相机拍照）"></a>捕捉和过滤静态图片（相机拍照）</h2><p>和上面类似：</p>
<figure class="highlight mm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">stillCamera = [[GP<span class="built_in">UImageStillCamera</span> alloc] init];</span><br><span class="line">stillCamera.outputImageOrientation = <span class="built_in">UIInterfaceOrientationPortrait</span>;</span><br><span class="line"></span><br><span class="line">filter = [[GP<span class="built_in">UImageGammaFilter</span> alloc] init];</span><br><span class="line">[stillCamera addTarget:filter];</span><br><span class="line">GP<span class="built_in">UImageView</span> *filterView = (GP<span class="built_in">UImageView</span> *)<span class="keyword">self</span>.view;</span><br><span class="line">[filter addTarget:filterView];</span><br><span class="line"></span><br><span class="line">[stillCamera startCameraCapture];</span><br></pre></td></tr></table></figure>
<p>当你想捕获一张照片，你使用下面的 callback ：</p>
<figure class="highlight mm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[stillCamera capturePhotoProcessedUpToFilter:filter withCompletionHandler:^(<span class="built_in">UIImage</span> *processedImage, <span class="built_in">NSError</span> *error)&#123;</span><br><span class="line">    <span class="built_in">NSData</span> *dataForJPEGFile = <span class="built_in">UIImageJPEGRepresentation</span>(processedImage, <span class="number">0.8</span>);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">NSArray</span> *paths = <span class="built_in">NSSearchPathForDirectoriesInDomains</span>(<span class="built_in">NSDocumentDirectory</span>, <span class="built_in">NSUserDomainMask</span>, <span class="literal">YES</span>);</span><br><span class="line">    <span class="built_in">NSString</span> *documentsDirectory = [paths objectAtIndex:<span class="number">0</span>];</span><br><span class="line"></span><br><span class="line">    <span class="built_in">NSError</span> *error2 = <span class="literal">nil</span>;</span><br><span class="line">    <span class="keyword">if</span> (![dataForJPEGFile writeToFile:[documentsDirectory stringByAppendingPathComponent:<span class="string">@"FilteredPhoto.jpg"</span>] options:<span class="built_in">NSAtomicWrite</span> error:&amp;error2])</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;];</span><br></pre></td></tr></table></figure>
<p>上面的代码捕获加工过的全尺寸的照片并且最终将他们保存在用户目录下。</p>
<h2 id="加工静态图片"><a href="#加工静态图片" class="headerlink" title="加工静态图片"></a>加工静态图片</h2><figure class="highlight mm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">UIImage</span> *inputImage = [<span class="built_in">UIImage</span> imageNamed:<span class="string">@"Lambeau.jpg"</span>];</span><br><span class="line"></span><br><span class="line">GP<span class="built_in">UImagePicture</span> *stillImageSource = [[GP<span class="built_in">UImagePicture</span> alloc] initWithImage:inputImage];</span><br><span class="line">GP<span class="built_in">UImageSepiaFilter</span> *stillImageFilter = [[GP<span class="built_in">UImageSepiaFilter</span> alloc] init];</span><br><span class="line"></span><br><span class="line">[stillImageSource addTarget:stillImageFilter];</span><br><span class="line">[stillImageFilter useNextFrameForImageCapture];</span><br><span class="line">[stillImageSource processImage];</span><br><span class="line"></span><br><span class="line"><span class="built_in">UIImage</span> *currentFilteredVideoFrame = [stillImageFilter imageFromCurrentFramebuffer];</span><br></pre></td></tr></table></figure>
<p>如果手动的从 filter 中捕获一个图片，我们需要手动调用 <code>-useNextFrameForImageCapture i</code> 去告诉 filter 等会我们需要从他那捕获，。默认的，GPUImage 通过 filter 重复使用 framebuffers 来保护内存。如果你需要通过手动捕获并且持有一个 filter 的 framebuffers，就得让他提前知道。、</p>
<p>对于单个操作，我们可以简单的操作：</p>
<figure class="highlight mm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">GP<span class="built_in">UImageSepiaFilter</span> *stillImageFilter2 = [[GP<span class="built_in">UImageSepiaFilter</span> alloc] init];</span><br><span class="line"><span class="built_in">UIImage</span> *quickFilteredImage = [stillImageFilter2 imageByFilteringImage:inputImage];</span><br></pre></td></tr></table></figure>
<h2 id="自定义过滤器"><a href="#自定义过滤器" class="headerlink" title="自定义过滤器"></a>自定义过滤器</h2><p>初始化：</p>
<figure class="highlight mm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GP<span class="built_in">UImageFilter</span> *customFilter = [[GP<span class="built_in">UImageFilter</span> alloc] initWithFragmentShaderFromFile:<span class="string">@"CustomShader"</span>];</span><br></pre></td></tr></table></figure>
<p>或者也可以使用 <code>initWithFragmentShaderFromString:</code> 初始化方法提供一个 fragment shader 作为字符串即可。</p>
<p>Fragment shaders 在各自的 filter 阶段执行运算渲染每个像素，它们使用 OpenGL Shading Language (GLSL)，一个 C 样式的语言针对 2D和 3D 图形。例如 sepia-tone filter ：</p>
<figure class="highlight mm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">varying highp vec2 textureCoordinate;</span><br><span class="line"></span><br><span class="line">uniform sampler2D inputImageTexture;</span><br><span class="line"></span><br><span class="line"><span class="keyword">void</span> main()</span><br><span class="line">&#123;</span><br><span class="line">    lowp vec4 textureColor = texture2D(inputImageTexture, textureCoordinate);</span><br><span class="line">    lowp vec4 outputColor;</span><br><span class="line">    outputColor.r = (textureColor.r * <span class="number">0.393</span>) + (textureColor.g * <span class="number">0.769</span>) + (textureColor.b * <span class="number">0.189</span>);</span><br><span class="line">    outputColor.g = (textureColor.r * <span class="number">0.349</span>) + (textureColor.g * <span class="number">0.686</span>) + (textureColor.b * <span class="number">0.168</span>);    </span><br><span class="line">    outputColor.b = (textureColor.r * <span class="number">0.272</span>) + (textureColor.g * <span class="number">0.534</span>) + (textureColor.b * <span class="number">0.131</span>);</span><br><span class="line">	outputColor.a = <span class="number">1.0</span>;</span><br><span class="line"></span><br><span class="line">	gl_FragColor = outputColor;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="过滤并且重新编码一个影片"><a href="#过滤并且重新编码一个影片" class="headerlink" title="过滤并且重新编码一个影片"></a>过滤并且重新编码一个影片</h2><p>影片可以通过 <code>GPUImageMovie</code> 类来加载，过滤，然后再使用 <code>GPUImageMovieWriter</code> 写出。</p>
<p>下面给出一个加载视频，通过一个像素化的 filter ，然后记录到磁盘中（分辨率为 480 X 640）:</p>
<figure class="highlight mm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">movieFile = [[GP<span class="built_in">UImageMovie</span> alloc] initWithURL:sampleURL];</span><br><span class="line">pixellateFilter = [[GP<span class="built_in">UImagePixellateFilter</span> alloc] init];</span><br><span class="line"></span><br><span class="line">[movieFile addTarget:pixellateFilter];</span><br><span class="line"></span><br><span class="line"><span class="built_in">NSString</span> *pathToMovie = [<span class="built_in">NSHomeDirectory</span>() stringByAppendingPathComponent:<span class="string">@"Documents/Movie.m4v"</span>];</span><br><span class="line">unlink([pathToMovie UTF8String]);</span><br><span class="line"><span class="built_in">NSURL</span> *movieURL = [<span class="built_in">NSURL</span> fileURLWithPath:pathToMovie];</span><br><span class="line"></span><br><span class="line">movieWriter = [[GP<span class="built_in">UImageMovieWriter</span> alloc] initWithMovieURL:movieURL size:<span class="built_in">CGSizeMake</span>(<span class="number">480.0</span>, <span class="number">640.0</span>)];</span><br><span class="line">[pixellateFilter addTarget:movieWriter];</span><br><span class="line"></span><br><span class="line">movieWriter.shouldPassthroughAudio = <span class="literal">YES</span>;</span><br><span class="line">movieFile.audioEncodingTarget = movieWriter;</span><br><span class="line">[movieFile enableSynchronizedEncodingUsingMovieWriter:movieWriter];</span><br><span class="line"></span><br><span class="line">[movieWriter startRecording];</span><br><span class="line">[movieFile startProcessing];</span><br></pre></td></tr></table></figure>
<p>当操作结束之后，我们需要从 filter 链中移除，并且关闭：</p>
<figure class="highlight mm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[pixellateFilter removeTarget:movieWriter];</span><br><span class="line">[movieWriter finishRecording];</span><br></pre></td></tr></table></figure>
<p>注意：只有操作完成影片才可以用，如果在之前被打算了那么将会丢失操作记录 </p>
<h1 id="直播中利用-GPUImage-处理过程"><a href="#直播中利用-GPUImage-处理过程" class="headerlink" title="直播中利用 GPUImage 处理过程"></a>直播中利用 GPUImage 处理过程</h1><p>采集视频 =&gt; 获取每一帧图片 =&gt; 滤镜处理 =&gt; GPUImageView展示</p>
<p><img src="http://upload-images.jianshu.io/upload_images/304825-5faefe55f9296071.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<h1 id="GPUImage-处理画面的原理"><a href="#GPUImage-处理画面的原理" class="headerlink" title="GPUImage 处理画面的原理"></a>GPUImage 处理画面的原理</h1><ul>
<li><p>GPUImage采用链式方式来处理画面,通过addTarget:方法为链条添加每个环节的对象，处理完一个target,就会把上一个环节处理好的图像数据传递下一个target去处理，称为GPUImage处理链。</p>
</li>
<li><p>一般 target 可以分为两类。中间环节的target, 一般是各种filter, 是GPUImageFilter或者是子类。最终环节的target, GPUImageView：用于显示到屏幕上, 或者GPUImageMovieWriter：写成视频文件。</p>
</li>
</ul>
<p><img src="http://upload-images.jianshu.io/upload_images/304825-84ff54fb516a70ce.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<h1 id="一个美颜算法的例子"><a href="#一个美颜算法的例子" class="headerlink" title="一个美颜算法的例子"></a>一个美颜算法的例子</h1><p>各种滤镜的效果原理就是把静态图片或者视频的每一帧进行图形变换再显示出来。它的本质就是像素点的坐标和颜色变化。下面是一个美颜算法的例子：</p>
<figure class="highlight mm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">NSString</span> *<span class="keyword">const</span> kLFGP<span class="built_in">UImageBeautyFragmentShaderString</span> = SHADER_STRING</span><br><span class="line">                                                        (</span><br><span class="line">    varying highp vec2 textureCoordinate;</span><br><span class="line"></span><br><span class="line">    uniform sampler2D inputImageTexture;</span><br><span class="line"></span><br><span class="line">    uniform highp vec2 singleStepOffset;</span><br><span class="line">    uniform highp vec4 params;</span><br><span class="line">    uniform highp <span class="keyword">float</span> brightness;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">const</span> highp vec3 W = vec3(<span class="number">0.299</span>, <span class="number">0.587</span>, <span class="number">0.114</span>);</span><br><span class="line">    <span class="keyword">const</span> highp mat3 saturateMatrix = mat3(</span><br><span class="line">        <span class="number">1.1102</span>, <span class="number">-0.0598</span>, <span class="number">-0.061</span>,</span><br><span class="line">        <span class="number">-0.0774</span>, <span class="number">1.0826</span>, <span class="number">-0.1186</span>,</span><br><span class="line">        <span class="number">-0.0228</span>, <span class="number">-0.0228</span>, <span class="number">1.1772</span>);</span><br><span class="line">    highp vec2 blurCoordinates[<span class="number">24</span>];</span><br><span class="line"></span><br><span class="line">    highp <span class="keyword">float</span> hardLight(highp <span class="keyword">float</span> color) &#123;</span><br><span class="line">    <span class="keyword">if</span> (color &lt;= <span class="number">0.5</span>)</span><br><span class="line">        color = color * color * <span class="number">2.0</span>;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        color = <span class="number">1.0</span> - ((<span class="number">1.0</span> - color)*(<span class="number">1.0</span> - color) * <span class="number">2.0</span>);</span><br><span class="line">    <span class="keyword">return</span> color;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">void</span> main()&#123;</span><br><span class="line">    highp vec3 centralColor = texture2D(inputImageTexture, textureCoordinate).rgb;</span><br><span class="line">    blurCoordinates[<span class="number">0</span>] = textureCoordinate.xy + singleStepOffset * vec2(<span class="number">0.0</span>, <span class="number">-10.0</span>);</span><br><span class="line">    blurCoordinates[<span class="number">1</span>] = textureCoordinate.xy + singleStepOffset * vec2(<span class="number">0.0</span>, <span class="number">10.0</span>);</span><br><span class="line">    blurCoordinates[<span class="number">2</span>] = textureCoordinate.xy + singleStepOffset * vec2(<span class="number">-10.0</span>, <span class="number">0.0</span>);</span><br><span class="line">    blurCoordinates[<span class="number">3</span>] = textureCoordinate.xy + singleStepOffset * vec2(<span class="number">10.0</span>, <span class="number">0.0</span>);</span><br><span class="line">    blurCoordinates[<span class="number">4</span>] = textureCoordinate.xy + singleStepOffset * vec2(<span class="number">5.0</span>, <span class="number">-8.0</span>);</span><br><span class="line">    blurCoordinates[<span class="number">5</span>] = textureCoordinate.xy + singleStepOffset * vec2(<span class="number">5.0</span>, <span class="number">8.0</span>);</span><br><span class="line">    blurCoordinates[<span class="number">6</span>] = textureCoordinate.xy + singleStepOffset * vec2(<span class="number">-5.0</span>, <span class="number">8.0</span>);</span><br><span class="line">    blurCoordinates[<span class="number">7</span>] = textureCoordinate.xy + singleStepOffset * vec2(<span class="number">-5.0</span>, <span class="number">-8.0</span>);</span><br><span class="line">    blurCoordinates[<span class="number">8</span>] = textureCoordinate.xy + singleStepOffset * vec2(<span class="number">8.0</span>, <span class="number">-5.0</span>);</span><br><span class="line">    blurCoordinates[<span class="number">9</span>] = textureCoordinate.xy + singleStepOffset * vec2(<span class="number">8.0</span>, <span class="number">5.0</span>);</span><br><span class="line">    blurCoordinates[<span class="number">10</span>] = textureCoordinate.xy + singleStepOffset * vec2(<span class="number">-8.0</span>, <span class="number">5.0</span>);</span><br><span class="line">    blurCoordinates[<span class="number">11</span>] = textureCoordinate.xy + singleStepOffset * vec2(<span class="number">-8.0</span>, <span class="number">-5.0</span>);</span><br><span class="line">    blurCoordinates[<span class="number">12</span>] = textureCoordinate.xy + singleStepOffset * vec2(<span class="number">0.0</span>, <span class="number">-6.0</span>);</span><br><span class="line">    blurCoordinates[<span class="number">13</span>] = textureCoordinate.xy + singleStepOffset * vec2(<span class="number">0.0</span>, <span class="number">6.0</span>);</span><br><span class="line">    blurCoordinates[<span class="number">14</span>] = textureCoordinate.xy + singleStepOffset * vec2(<span class="number">6.0</span>, <span class="number">0.0</span>);</span><br><span class="line">    blurCoordinates[<span class="number">15</span>] = textureCoordinate.xy + singleStepOffset * vec2(<span class="number">-6.0</span>, <span class="number">0.0</span>);</span><br><span class="line">    blurCoordinates[<span class="number">16</span>] = textureCoordinate.xy + singleStepOffset * vec2(<span class="number">-4.0</span>, <span class="number">-4.0</span>);</span><br><span class="line">    blurCoordinates[<span class="number">17</span>] = textureCoordinate.xy + singleStepOffset * vec2(<span class="number">-4.0</span>, <span class="number">4.0</span>);</span><br><span class="line">    blurCoordinates[<span class="number">18</span>] = textureCoordinate.xy + singleStepOffset * vec2(<span class="number">4.0</span>, <span class="number">-4.0</span>);</span><br><span class="line">    blurCoordinates[<span class="number">19</span>] = textureCoordinate.xy + singleStepOffset * vec2(<span class="number">4.0</span>, <span class="number">4.0</span>);</span><br><span class="line">    blurCoordinates[<span class="number">20</span>] = textureCoordinate.xy + singleStepOffset * vec2(<span class="number">-2.0</span>, <span class="number">-2.0</span>);</span><br><span class="line">    blurCoordinates[<span class="number">21</span>] = textureCoordinate.xy + singleStepOffset * vec2(<span class="number">-2.0</span>, <span class="number">2.0</span>);</span><br><span class="line">    blurCoordinates[<span class="number">22</span>] = textureCoordinate.xy + singleStepOffset * vec2(<span class="number">2.0</span>, <span class="number">-2.0</span>);</span><br><span class="line">    blurCoordinates[<span class="number">23</span>] = textureCoordinate.xy + singleStepOffset * vec2(<span class="number">2.0</span>, <span class="number">2.0</span>);</span><br><span class="line"></span><br><span class="line">    highp <span class="keyword">float</span> sampleColor = centralColor.g * <span class="number">22.0</span>;</span><br><span class="line">    sampleColor += texture2D(inputImageTexture, blurCoordinates[<span class="number">0</span>]).g;</span><br><span class="line">    sampleColor += texture2D(inputImageTexture, blurCoordinates[<span class="number">1</span>]).g;</span><br><span class="line">    sampleColor += texture2D(inputImageTexture, blurCoordinates[<span class="number">2</span>]).g;</span><br><span class="line">    sampleColor += texture2D(inputImageTexture, blurCoordinates[<span class="number">3</span>]).g;</span><br><span class="line">    sampleColor += texture2D(inputImageTexture, blurCoordinates[<span class="number">4</span>]).g;</span><br><span class="line">    sampleColor += texture2D(inputImageTexture, blurCoordinates[<span class="number">5</span>]).g;</span><br><span class="line">    sampleColor += texture2D(inputImageTexture, blurCoordinates[<span class="number">6</span>]).g;</span><br><span class="line">    sampleColor += texture2D(inputImageTexture, blurCoordinates[<span class="number">7</span>]).g;</span><br><span class="line">    sampleColor += texture2D(inputImageTexture, blurCoordinates[<span class="number">8</span>]).g;</span><br><span class="line">    sampleColor += texture2D(inputImageTexture, blurCoordinates[<span class="number">9</span>]).g;</span><br><span class="line">    sampleColor += texture2D(inputImageTexture, blurCoordinates[<span class="number">10</span>]).g;</span><br><span class="line">    sampleColor += texture2D(inputImageTexture, blurCoordinates[<span class="number">11</span>]).g;</span><br><span class="line">    sampleColor += texture2D(inputImageTexture, blurCoordinates[<span class="number">12</span>]).g * <span class="number">2.0</span>;</span><br><span class="line">    sampleColor += texture2D(inputImageTexture, blurCoordinates[<span class="number">13</span>]).g * <span class="number">2.0</span>;</span><br><span class="line">    sampleColor += texture2D(inputImageTexture, blurCoordinates[<span class="number">14</span>]).g * <span class="number">2.0</span>;</span><br><span class="line">    sampleColor += texture2D(inputImageTexture, blurCoordinates[<span class="number">15</span>]).g * <span class="number">2.0</span>;</span><br><span class="line">    sampleColor += texture2D(inputImageTexture, blurCoordinates[<span class="number">16</span>]).g * <span class="number">2.0</span>;</span><br><span class="line">    sampleColor += texture2D(inputImageTexture, blurCoordinates[<span class="number">17</span>]).g * <span class="number">2.0</span>;</span><br><span class="line">    sampleColor += texture2D(inputImageTexture, blurCoordinates[<span class="number">18</span>]).g * <span class="number">2.0</span>;</span><br><span class="line">    sampleColor += texture2D(inputImageTexture, blurCoordinates[<span class="number">19</span>]).g * <span class="number">2.0</span>;</span><br><span class="line">    sampleColor += texture2D(inputImageTexture, blurCoordinates[<span class="number">20</span>]).g * <span class="number">3.0</span>;</span><br><span class="line">    sampleColor += texture2D(inputImageTexture, blurCoordinates[<span class="number">21</span>]).g * <span class="number">3.0</span>;</span><br><span class="line">    sampleColor += texture2D(inputImageTexture, blurCoordinates[<span class="number">22</span>]).g * <span class="number">3.0</span>;</span><br><span class="line">    sampleColor += texture2D(inputImageTexture, blurCoordinates[<span class="number">23</span>]).g * <span class="number">3.0</span>;</span><br><span class="line"></span><br><span class="line">    sampleColor = sampleColor / <span class="number">62.0</span>;</span><br><span class="line"></span><br><span class="line">    highp <span class="keyword">float</span> highPass = centralColor.g - sampleColor + <span class="number">0.5</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">5</span>; i++) &#123;</span><br><span class="line">        highPass = hardLight(highPass);</span><br><span class="line">    &#125;</span><br><span class="line">    highp <span class="keyword">float</span> lumance = dot(centralColor, W);</span><br><span class="line"></span><br><span class="line">    highp <span class="keyword">float</span> alpha = pow(lumance, params.r);</span><br><span class="line"></span><br><span class="line">    highp vec3 smoothColor = centralColor + (centralColor-vec3(highPass))*alpha*<span class="number">0.1</span>;</span><br><span class="line"></span><br><span class="line">    smoothColor.r = clamp(pow(smoothColor.r, params.g), <span class="number">0.0</span>, <span class="number">1.0</span>);</span><br><span class="line">    smoothColor.g = clamp(pow(smoothColor.g, params.g), <span class="number">0.0</span>, <span class="number">1.0</span>);</span><br><span class="line">    smoothColor.b = clamp(pow(smoothColor.b, params.g), <span class="number">0.0</span>, <span class="number">1.0</span>);</span><br><span class="line"></span><br><span class="line">    highp vec3 lvse = vec3(<span class="number">1.0</span>)-(vec3(<span class="number">1.0</span>)-smoothColor)*(vec3(<span class="number">1.0</span>)-centralColor);</span><br><span class="line">    highp vec3 bianliang = max(smoothColor, centralColor);</span><br><span class="line">    highp vec3 rouguang = <span class="number">2.0</span>*centralColor*smoothColor + centralColor*centralColor - <span class="number">2.0</span>*centralColor*centralColor*smoothColor;</span><br><span class="line"></span><br><span class="line">    gl_FragColor = vec4(mix(centralColor, lvse, alpha), <span class="number">1.0</span>);</span><br><span class="line">    gl_FragColor.rgb = mix(gl_FragColor.rgb, bianliang, alpha);</span><br><span class="line">    gl_FragColor.rgb = mix(gl_FragColor.rgb, rouguang, params.b);</span><br><span class="line"></span><br><span class="line">    highp vec3 satcolor = gl_FragColor.rgb * saturateMatrix;</span><br><span class="line">    gl_FragColor.rgb = mix(gl_FragColor.rgb, satcolor, params.a);</span><br><span class="line">    gl_FragColor.rgb = vec3(gl_FragColor.rgb + vec3(brightness));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://github.com/BradLarson/GPUImage" target="_blank" rel="external">GUPImage 地址</a></p>
<p><a href="http://www.jianshu.com/p/4646894245ba" target="_blank" rel="external">如何快速的开发一个完整的iOS直播app(美颜篇)</a></p>
  
	</div>
		<footer class="article-footer clearfix">
<div class="article-catetags">


</div>



	<div class="article-share" id="share">
	
	  <div data-url="http://yoursite.com/2017/11/13/GPUImage-简介与入门/" data-title="GPUImage 简介与入门 | DevZhang的博客小屋" data-tsina="null" class="share clearfix">
	  </div>
	
	</div>


</footer>

   	       
	</article>
	
<nav class="article-nav clearfix">
 

<div class="next">
<a href="/2017/11/02/Autorelease-小结/"  title="Autorelease 探究">
 <strong>下一篇：</strong><br/> 
 <span>Autorelease 探究
</span>
</a>
</div>

</nav>

	

</div>  
      <div class="openaside"><a class="navbutton" href="#" title="显示侧边栏"></a></div>

  <div id="toc" class="toc-aside">
  <strong class="toc-title">文章目录</strong>
 
 <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#概述"><span class="toc-number">1.</span> <span class="toc-text">概述</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#基本架构"><span class="toc-number">2.</span> <span class="toc-text">基本架构</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#执行一些普通任务"><span class="toc-number">3.</span> <span class="toc-text">执行一些普通任务</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#过滤实时摄像（相机实时）"><span class="toc-number">3.1.</span> <span class="toc-text">过滤实时摄像（相机实时）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#捕捉和过滤静态图片（相机拍照）"><span class="toc-number">3.2.</span> <span class="toc-text">捕捉和过滤静态图片（相机拍照）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#加工静态图片"><span class="toc-number">3.3.</span> <span class="toc-text">加工静态图片</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#自定义过滤器"><span class="toc-number">3.4.</span> <span class="toc-text">自定义过滤器</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#过滤并且重新编码一个影片"><span class="toc-number">3.5.</span> <span class="toc-text">过滤并且重新编码一个影片</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#直播中利用-GPUImage-处理过程"><span class="toc-number">4.</span> <span class="toc-text">直播中利用 GPUImage 处理过程</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#GPUImage-处理画面的原理"><span class="toc-number">5.</span> <span class="toc-text">GPUImage 处理画面的原理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#一个美颜算法的例子"><span class="toc-number">6.</span> <span class="toc-text">一个美颜算法的例子</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#参考"><span class="toc-number">7.</span> <span class="toc-text">参考</span></a></li></ol>
 
  </div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="隐藏侧边栏"></a></div>
<aside class="clearfix">

  


  

  

  <div class="linkslist">
  <p class="asidetitle">友情链接</p>
    <ul>
        
          <li>
            
            	<a href="https://coderq.com" target="_blank" title="一个面向程序员交流分享的新一代社区">码农圈</a>
            
          </li>
        
          <li>
            
            	<a href="http://wuchong.me" target="_blank" title="Jark&#39;s Blog">Jark&#39;s Blog</a>
            
          </li>
        
    </ul>
</div>

  


  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS 订阅</a>
</div>

  <div class="weiboshow">
  <p class="asidetitle">新浪微博</p>
    <iframe width="100%" height="119" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=119&fansRow=2&ptype=1&speed=0&skin=9&isTitle=1&noborder=1&isWeibo=0&isFans=0&uid=null&verifier=&dpc=1"></iframe>
</div>


</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	
	<section class="info">
		<p> 积跬步以至千里 <br/>
			凭栏眺望会有时</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		
		
		
		
		
		
		
		
		
	</div>
			
		

		<p class="copyright">
		Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/wuchong/jacman" target="_blank" title="Jacman">Jacman</a> © 2017 
		
		<a href="/about" target="_blank" title="CSAMEN">CSAMEN</a>
		
		
		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/jquery.qrcode-0.12.0.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
      
      $('#toc.toc-aside').css('display', 'none');
        
    }
  });
});
</script>

<script type="text/javascript">
$(document).ready(function(){ 
  var ai = $('.article-content>iframe'),
      ae = $('.article-content>embed'),
      t  = $('#toc'),
      ta = $('#toc.toc-aside'),
      o  = $('.openaside'),
      c  = $('.closeaside');
  if(ai.length>0){
    ai.wrap('<div class="video-container" />');
  };
  if(ae.length>0){
   ae.wrap('<div class="video-container" />');
  };
  c.click(function(){
    ta.css('display', 'block').addClass('fadeIn');
  });
  o.click(function(){
    ta.css('display', 'none');
  });
  $(window).scroll(function(){
    ta.css("top",Math.max(140,320-$(this).scrollTop()));
  });
});
</script>


<script type="text/javascript">
$(document).ready(function(){ 
  var $this = $('.share'),
      url = $this.attr('data-url'),
      encodedUrl = encodeURIComponent(url),
      title = $this.attr('data-title'),
      tsina = $this.attr('data-tsina'),
      description = $this.attr('description');
  var html = [
  '<div class="hoverqrcode clearfix"></div>',
  '<a class="overlay" id="qrcode"></a>',
  '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
  '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
  '<a href="#qrcode" class="article-share-qrcode" title="微信"></a>',
  '<a href="http://widget.renren.com/dialog/share?resourceUrl=' + encodedUrl + '&srcUrl=' + encodedUrl + '&title=' + title +'" class="article-share-renren" target="_blank" title="人人"></a>',
  '<a href="http://service.weibo.com/share/share.php?title='+title+'&url='+encodedUrl +'&ralateUid='+ tsina +'&searchPic=true&style=number' +'" class="article-share-weibo" target="_blank" title="微博"></a>',
  '<span title="Share to"></span>'
  ].join('');
  $this.append(html);

  $('.hoverqrcode').hide();

  var myWidth = 0;
  function updatehoverqrcode(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
    var qrsize = myWidth > 1024 ? 200:100;
    var options = {render: 'image', size: qrsize, fill: '#2ca6cb', text: url, radius: 0.5, quiet: 1};
    var p = $('.article-share-qrcode').position();
    $('.hoverqrcode').empty().css('width', qrsize).css('height', qrsize)
                          .css('left', p.left-qrsize/2+20).css('top', p.top-qrsize-10)
                          .qrcode(options);
  };
  $(window).resize(function(){
    $('.hoverqrcode').hide();
  });
  $('.article-share-qrcode').click(function(){
    updatehoverqrcode();
    $('.hoverqrcode').toggle();
  });
  $('.article-share-qrcode').hover(function(){}, function(){
      $('.hoverqrcode').hide();
  });
});   
</script>









<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->



<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?e6d1f421bbc9962127a50488f9ed37d1";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>



<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="返回顶部"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->

  </body>
</html>
